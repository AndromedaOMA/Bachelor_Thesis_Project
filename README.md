<h1 align="center">Hi ðŸ‘‹, here we have my Bachelor Thesis Project/Speech Enhancement project</h1>
<h3 align="center">Deep learning focused on improving the clarity of human language regardless of the patient's environment!</h3>


## Table Of Content
* [About Project](#project)
* [Architecture Overview](#architecture)
* [Dataset](#dataset)
* [Getting Started](#getting-started)

--------------------------------------------------------------------------------
<h1 id="project" align="left">ðŸ¤– About Project</h1>

In other words, this project will adjust and adapt in real time the hearing depending on the environment with the emphasis on the quality of the conversation. There are already technologies that address this topic, but most of them focus on canceling background noise ("noise reduction"), thus leaving only human sounds/conversations to be heard, without any intervention on human voices. This project will focus strictly on finding a more efficient solution based on the provided model.

---

<h1 id="architecture" align="left">ðŸ§  Architecture Overview</h1>

The FSPEN (Full-band and Sub-band Path Extension Network) model offers us a solution that combines concepts such as GRU, together with Convolutional Neural Networks (CNN) all combined through the Encoder-Decoder architecture.

Also, this architecture is ultra-lightweight (79K parameters) and allows for rapid training and testing on the chosen dataset, achieving scores of various metrics, similar to the scores generated by models that reach parameters in the millions!

For better clarity of the statistics, we provide you with plot graphs that will highlight the quality and efficiency of the FSPEN model in comparison to other models with the same objective (data are taken from [link]([url](https://research.samsung.com/blog/FSPEN-AN-ULTRA-LIGHTWEIGHT-NETWORK-FOR-REAL-TIME-SPEECH-ENAHNCMENT))). Figure 3.5.1 presents the PESQ and STOI metrics for the models:

<img src="https://github.com/user-attachments/assets/383e380b-feea-41a0-b9ed-cf00f404c980" alt="Model Diagram" width="500" align="right">

| Model             | Parameters |
|------------------|------------|
| RNNoise          | 0.06 M     |
| CCFNet+ (Lite)   | 160 K      |
| CCFNet+          | 620 K      |
| DeepFilterNet2   | 2.31 M     |
| DeepFilterNet    | 1.78 M     |
| PercepNet        | 8 M        |
| FSPEN            | 79 K       |



---

<h1 id="dataset" align="left">ðŸ“„ Dataset</h1>



---

<h1 id="getting-started" align="left">ðŸš€ Getting Started</h1>

1. Clone the repository:
``` git clone git@github.com:AndromedaOMA/Bachelor_Thesis_Project.git ```
2. Have fun!

---

> ðŸ“ **Note**:  
> By completing this bachelor's thesis, I am completing my bachelor's studies at the Faculty of Computer Sciences in IaÈ™i.
> The model architecture is taken from [here](https://research.samsung.com/blog/FSPEN-AN-ULTRA-LIGHTWEIGHT-NETWORK-FOR-REAL-TIME-SPEECH-ENAHNCMENT).

* [Table Of Content](#table-of-content)
